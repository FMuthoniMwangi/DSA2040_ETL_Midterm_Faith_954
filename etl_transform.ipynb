{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c23c05",
   "metadata": {},
   "source": [
    "Tranformation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb49ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_csv('data/raw_data.csv')\n",
    "inc_df = pd.read_csv('data/incremental_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561a6f7",
   "metadata": {},
   "source": [
    "1. Cleaning: Handle Missing Values and Remove Duplicates\n",
    "\n",
    "Before any analysis, it's important to ensure data quality by handling missing values and removing duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc46ec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data missing values:\n",
      " order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64\n",
      "Incremental Data missing values:\n",
      " order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64\n",
      "Raw Data duplicate rows: 0\n",
      "Incremental Data duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Show missing values before cleaning\n",
    "print(\"Raw Data missing values:\\n\", raw_df.isnull().sum())\n",
    "print(\"Incremental Data missing values:\\n\", inc_df.isnull().sum())\n",
    "\n",
    "# Show duplicates before cleaning\n",
    "print(\"Raw Data duplicate rows:\", raw_df.duplicated().sum())\n",
    "print(\"Incremental Data duplicate rows:\", inc_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec651638",
   "metadata": {},
   "source": [
    " Cleaning Steps\n",
    "\n",
    "- Fill missing `customer_name` and `region` with \"Unknown\".\n",
    "- Fill missing `quantity` and `unit_price` with their respective median values.\n",
    "- Drop rows with missing `order_date` (since dates are important for analysis).\n",
    "- Remove duplicate rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1210396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data missing values after cleaning:\n",
      " order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64\n",
      "Incremental Data missing values after cleaning:\n",
      " order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64\n",
      "Raw Data shape after cleaning: (98, 7)\n",
      "Incremental Data shape after cleaning: (10, 7)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'customer_name' and 'region'\n",
    "raw_df['customer_name'] = raw_df['customer_name'].fillna(\"Unknown\")\n",
    "raw_df['region'] = raw_df['region'].fillna(\"Unknown\")\n",
    "inc_df['customer_name'] = inc_df['customer_name'].fillna(\"Unknown\")\n",
    "inc_df['region'] = inc_df['region'].fillna(\"Unknown\")\n",
    "\n",
    "# Fill missing numeric values with the median\n",
    "raw_df['quantity'] = raw_df['quantity'].fillna(raw_df['quantity'].median())\n",
    "raw_df['unit_price'] = raw_df['unit_price'].fillna(raw_df['unit_price'].median())\n",
    "inc_df['quantity'] = inc_df['quantity'].fillna(inc_df['quantity'].median())\n",
    "inc_df['unit_price'] = inc_df['unit_price'].fillna(inc_df['unit_price'].median())\n",
    "\n",
    "# Drop rows where 'order_date' is missing\n",
    "raw_df = raw_df.dropna(subset=['order_date'])\n",
    "inc_df = inc_df.dropna(subset=['order_date'])\n",
    "\n",
    "# Remove duplicate rows\n",
    "raw_df = raw_df.drop_duplicates()\n",
    "inc_df = inc_df.drop_duplicates()\n",
    "\n",
    "# Show missing values and shape after cleaning\n",
    "print(\"Raw Data missing values after cleaning:\\n\", raw_df.isnull().sum())\n",
    "print(\"Incremental Data missing values after cleaning:\\n\", inc_df.isnull().sum())\n",
    "print(\"Raw Data shape after cleaning:\", raw_df.shape)\n",
    "print(\"Incremental Data shape after cleaning:\", inc_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aaaf8e",
   "metadata": {},
   "source": [
    "2. Enrichment: Add total_price\n",
    "\n",
    "To enrich the datasets, we calculate a new column called `total_price` as the product of `quantity` and `unit_price`. This provides immediate insight into the value of each order.\n",
    "\n",
    "Let's view the data before and after the enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d33add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantity  unit_price\n",
      "0       2.0       500.0\n",
      "1       2.0       500.0\n",
      "2       2.0       250.0\n",
      "3       2.0       750.0\n",
      "4       3.0       500.0\n",
      "   quantity  unit_price\n",
      "0       1.5       900.0\n",
      "1       1.0       300.0\n",
      "2       1.0       600.0\n",
      "3       1.5       300.0\n",
      "4       2.0       600.0\n",
      "   quantity  unit_price  total_price\n",
      "0       2.0       500.0       1000.0\n",
      "1       2.0       500.0       1000.0\n",
      "2       2.0       250.0        500.0\n",
      "3       2.0       750.0       1500.0\n",
      "4       3.0       500.0       1500.0\n",
      "   quantity  unit_price  total_price\n",
      "0       1.5       900.0       1350.0\n",
      "1       1.0       300.0        300.0\n",
      "2       1.0       600.0        600.0\n",
      "3       1.5       300.0        450.0\n",
      "4       2.0       600.0       1200.0\n"
     ]
    }
   ],
   "source": [
    "# Before enrichment\n",
    "print(raw_df[['quantity', 'unit_price']].head())\n",
    "print(inc_df[['quantity', 'unit_price']].head())\n",
    "\n",
    "# Add total_price column\n",
    "raw_df['total_price'] = raw_df['quantity'] * raw_df['unit_price']\n",
    "inc_df['total_price'] = inc_df['quantity'] * inc_df['unit_price']\n",
    "\n",
    "# After enrichment\n",
    "print(raw_df[['quantity', 'unit_price', 'total_price']].head())\n",
    "print(inc_df[['quantity', 'unit_price', 'total_price']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0f723",
   "metadata": {},
   "source": [
    "3. Structural: Convert Dates and Ensure Data Types\n",
    "\n",
    "It's important to have correct data types for analysis. Converting the `order_date` column to datetime and ensure `quantity` and `unit_price` are numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf741536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                  int64\n",
      "customer_name            object\n",
      "product                  object\n",
      "quantity                float64\n",
      "unit_price              float64\n",
      "order_date       datetime64[ns]\n",
      "region                   object\n",
      "total_price             float64\n",
      "dtype: object\n",
      "order_id                  int64\n",
      "customer_name            object\n",
      "product                  object\n",
      "quantity                float64\n",
      "unit_price              float64\n",
      "order_date       datetime64[ns]\n",
      "region                   object\n",
      "total_price             float64\n",
      "dtype: object\n",
      "order_id                  int64\n",
      "customer_name            object\n",
      "product                  object\n",
      "quantity                float64\n",
      "unit_price              float64\n",
      "order_date       datetime64[ns]\n",
      "region                   object\n",
      "total_price             float64\n",
      "dtype: object\n",
      "order_id                  int64\n",
      "customer_name            object\n",
      "product                  object\n",
      "quantity                float64\n",
      "unit_price              float64\n",
      "order_date       datetime64[ns]\n",
      "region                   object\n",
      "total_price             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Before conversion\n",
    "print(raw_df.dtypes)\n",
    "print(inc_df.dtypes)\n",
    "\n",
    "# Conversion\n",
    "raw_df['order_date'] = pd.to_datetime(raw_df['order_date'], errors='coerce')\n",
    "inc_df['order_date'] = pd.to_datetime(inc_df['order_date'], errors='coerce')\n",
    "raw_df['quantity'] = pd.to_numeric(raw_df['quantity'], errors='coerce')\n",
    "raw_df['unit_price'] = pd.to_numeric(raw_df['unit_price'], errors='coerce')\n",
    "inc_df['quantity'] = pd.to_numeric(inc_df['quantity'], errors='coerce')\n",
    "inc_df['unit_price'] = pd.to_numeric(inc_df['unit_price'], errors='coerce')\n",
    "\n",
    "# After conversion\n",
    "print(raw_df.dtypes)\n",
    "print(inc_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570ece7",
   "metadata": {},
   "source": [
    "3. Filtering: Drop Irrelevant Columns or Rows\n",
    "\n",
    "If required, filtering out columns or rows that are not relevant. \n",
    "\n",
    "*(No columns dropped in this transformation.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99648366",
   "metadata": {},
   "source": [
    "4. Categorization: Create Customer Tiers\n",
    "\n",
    "Creating a new column called `customer_tier` that categorizes customers based on their `total_price`:\n",
    "- 'Bronze' for total_price < 500\n",
    "- 'Silver' for total_price between 500 and 1000\n",
    "- 'Gold' for total_price >= 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "686df900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_name  total_price\n",
      "0         Diana       1000.0\n",
      "1           Eve       1000.0\n",
      "2       Charlie        500.0\n",
      "3           Eve       1500.0\n",
      "4           Eve       1500.0\n",
      "  customer_name  total_price customer_tier\n",
      "0         Diana       1000.0          Gold\n",
      "1           Eve       1000.0          Gold\n",
      "2       Charlie        500.0        Silver\n",
      "3           Eve       1500.0          Gold\n",
      "4           Eve       1500.0          Gold\n",
      "  customer_name  total_price customer_tier\n",
      "0         Alice       1350.0          Gold\n",
      "1       Unknown        300.0        Bronze\n",
      "2       Unknown        600.0        Silver\n",
      "3       Unknown        450.0        Bronze\n",
      "4         Heidi       1200.0          Gold\n"
     ]
    }
   ],
   "source": [
    "# Before\n",
    "print(raw_df[['customer_name', 'total_price']].head())\n",
    "\n",
    "# Categorization function\n",
    "def tier(price):\n",
    "    if price < 500:\n",
    "        return 'Bronze'\n",
    "    elif price < 1000:\n",
    "        return 'Silver'\n",
    "    else:\n",
    "        return 'Gold'\n",
    "\n",
    "raw_df['customer_tier'] = raw_df['total_price'].apply(tier)\n",
    "inc_df['customer_tier'] = inc_df['total_price'].apply(tier)\n",
    "\n",
    "# After\n",
    "print(raw_df[['customer_name', 'total_price', 'customer_tier']].head())\n",
    "print(inc_df[['customer_name', 'total_price', 'customer_tier']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac421181",
   "metadata": {},
   "source": [
    "Save Transformed Datasets\n",
    "\n",
    "Save the cleaned and enriched datasets to the `transformed/` folder as required:\n",
    "- `transformed_full.csv` for the full dataset\n",
    "- `transformed_incremental.csv` for the incremental dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9582fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv('transformed/transformed_full.csv', index=False)\n",
    "inc_df.to_csv('transformed/transformed_incremental.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1143183e",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "- Cleaning: Missing values handled, duplicates removed\n",
    "- Enrichment: Added total_price\n",
    "- Structural: Converted dates and ensured numeric types\n",
    "- Filtering: (No columns dropped)\n",
    "- Categorization: Added customer_tier\n",
    "- Transformed files saved for the next ETL step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
